{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51617eaa-6efc-47be-90e2-80c573b879ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d421751-49b6-4b3b-9950-900128f75495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name ./all-MiniLM-L6-v2. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = SentenceTransformer(\"./all-MiniLM-L6-v2\")\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b799a7d-d382-441a-9be2-88e66a4ea3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name ./bge-large-en-v1.5. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = SentenceTransformer(\"./bge-large-en-v1.5\")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb2c8c0-ecb0-4166-bab5-51711bf4757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[18.7014, 19.2733]])\n",
      "Similarity: tensor([[211.7341, 179.6893]])\n"
     ]
    }
   ],
   "source": [
    "def test1(model):\n",
    "    query_embedding = model.encode(\"How big is London\")\n",
    "    passage_embedding = model.encode([\n",
    "        \"London has 9,787,426 inhabitants at the 2011 census\",\n",
    "        \"London is known for its finacial district\",\n",
    "    ])\n",
    "\n",
    "    print(\"Similarity:\", util.dot_score(query_embedding, passage_embedding))\n",
    "\n",
    "test1(model1)\n",
    "test1(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc9d358-9a30-40d5-b47c-957db76b5c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0327\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n",
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.5644\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.4045\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9627\n"
     ]
    }
   ],
   "source": [
    "def test2(model):\n",
    "    # Two lists of sentences\n",
    "    sentences1 = [\n",
    "        \"The cat sits outside\",\n",
    "        \"A man is playing guitar\",\n",
    "        \"The new movie is awesome\",\n",
    "    ]\n",
    "    \n",
    "    sentences2 = [\n",
    "        \"The dog plays in the garden\",\n",
    "        \"A woman watches TV\",\n",
    "        \"The new movie is so great\",\n",
    "    ]\n",
    "    \n",
    "    # Compute embedding for both lists\n",
    "    embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine-similarities\n",
    "    cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "    \n",
    "    # Output the pairs with their score\n",
    "    for i in range(len(sentences1)):\n",
    "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "            sentences1[i], sentences2[i], cosine_scores[i][i]\n",
    "        ))\n",
    "\n",
    "test2(model1)\n",
    "test2(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdf2a78e-faa8-4565-bb4b-6435211c321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love pasta \t\t I love pasta \t\t Score: 1.0000\n",
      "The cat sits outside \t\t The cat sits outside \t\t Score: 1.0000\n",
      "The cat plays in the garden \t\t The cat plays in the garden \t\t Score: 1.0000\n",
      "A woman watches TV \t\t A woman watches TV \t\t Score: 1.0000\n",
      "The new movie is so great \t\t The new movie is so great \t\t Score: 1.0000\n",
      "Do you like pizza? \t\t Do you like pizza? \t\t Score: 1.0000\n",
      "A man is playing guitar \t\t A man is playing guitar \t\t Score: 1.0000\n",
      "The new movie is awesome \t\t The new movie is awesome \t\t Score: 1.0000\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n",
      "The new movie is so great \t\t The new movie is awesome \t\t Score: 0.8939\n",
      "====================================================================================================================\n",
      "I love pasta \t\t I love pasta \t\t Score: 1.0000\n",
      "A woman watches TV \t\t A woman watches TV \t\t Score: 1.0000\n",
      "The new movie is so great \t\t The new movie is so great \t\t Score: 1.0000\n",
      "A man is playing guitar \t\t A man is playing guitar \t\t Score: 1.0000\n",
      "The cat sits outside \t\t The cat sits outside \t\t Score: 1.0000\n",
      "The cat plays in the garden \t\t The cat plays in the garden \t\t Score: 1.0000\n",
      "Do you like pizza? \t\t Do you like pizza? \t\t Score: 1.0000\n",
      "The new movie is awesome \t\t The new movie is awesome \t\t Score: 1.0000\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9627\n",
      "The new movie is so great \t\t The new movie is awesome \t\t Score: 0.9627\n"
     ]
    }
   ],
   "source": [
    "def test3(model):\n",
    "    # Single list of sentences\n",
    "    sentences = [\n",
    "        \"The cat sits outside\",\n",
    "        \"A man is playing guitar\",\n",
    "        \"I love pasta\",\n",
    "        \"The new movie is awesome\",\n",
    "        \"The cat plays in the garden\",\n",
    "        \"A woman watches TV\",\n",
    "        \"The new movie is so great\",\n",
    "        \"Do you like pizza?\",\n",
    "    ]\n",
    "    \n",
    "    # Compute embeddings\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine-similarities for each sentence with each other sentence\n",
    "    cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "    \n",
    "    # Find the pairs with the highest cosine similarity scores\n",
    "    pairs = []\n",
    "    for i in range(cosine_scores.shape[0]):\n",
    "        for j in range(cosine_scores.shape[1]):\n",
    "            pairs.append({\"index\": [i, j], \"score\": cosine_scores[i][j]})\n",
    "    \n",
    "    # Sort scores in decreasing order\n",
    "    pairs = sorted(pairs, key=lambda x: x[\"score\"], reverse=True)\n",
    "    \n",
    "    for pair in pairs[0:10]:\n",
    "        i, j = pair[\"index\"]\n",
    "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "            sentences[i], sentences[j], pair[\"score\"]\n",
    "        ))\n",
    "\n",
    "test3(model1)\n",
    "print(\"====================================================================================================================\")\n",
    "test3(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7e61a2-f2dc-49bd-b7ab-3e6d07a73f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A man is eating pasta.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A man is eating food. (Score: 0.7035)\n",
      "A man is eating a piece of bread. (Score: 0.5272)\n",
      "A man is riding a horse. (Score: 0.1889)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1047)\n",
      "A cheetah is running behind its prey. (Score: 0.0980)\n",
      "A man is eating food. (Score: 0.7035)\n",
      "A man is eating a piece of bread. (Score: 0.5272)\n",
      "A man is riding a horse. (Score: 0.1889)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1047)\n",
      "A cheetah is running behind its prey. (Score: 0.0980)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Someone in a gorilla costume is playing a set of drums.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A monkey is playing drums. (Score: 0.6433)\n",
      "A woman is playing violin. (Score: 0.2564)\n",
      "A man is riding a horse. (Score: 0.1389)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1191)\n",
      "A cheetah is running behind its prey. (Score: 0.1080)\n",
      "A monkey is playing drums. (Score: 0.6433)\n",
      "A woman is playing violin. (Score: 0.2564)\n",
      "A man is riding a horse. (Score: 0.1389)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1191)\n",
      "A cheetah is running behind its prey. (Score: 0.1080)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A cheetah chases prey on across a field.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A cheetah is running behind its prey. (Score: 0.8253)\n",
      "A man is eating food. (Score: 0.1399)\n",
      "A monkey is playing drums. (Score: 0.1292)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1097)\n",
      "A man is riding a horse. (Score: 0.0650)\n",
      "A cheetah is running behind its prey. (Score: 0.8253)\n",
      "A man is eating food. (Score: 0.1399)\n",
      "A monkey is playing drums. (Score: 0.1292)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1097)\n",
      "A man is riding a horse. (Score: 0.0650)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A man is eating pasta.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A man is eating food. (Score: 0.8350)\n",
      "A man is eating a piece of bread. (Score: 0.7134)\n",
      "A man is riding a horse. (Score: 0.5122)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.4533)\n",
      "A woman is playing violin. (Score: 0.4389)\n",
      "A man is eating food. (Score: 0.8350)\n",
      "A man is eating a piece of bread. (Score: 0.7134)\n",
      "A man is riding a horse. (Score: 0.5122)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.4533)\n",
      "A woman is playing violin. (Score: 0.4389)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Someone in a gorilla costume is playing a set of drums.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A monkey is playing drums. (Score: 0.8023)\n",
      "A woman is playing violin. (Score: 0.5361)\n",
      "A man is eating food. (Score: 0.4923)\n",
      "A cheetah is running behind its prey. (Score: 0.4862)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.4407)\n",
      "A monkey is playing drums. (Score: 0.8023)\n",
      "A woman is playing violin. (Score: 0.5361)\n",
      "A man is eating food. (Score: 0.4923)\n",
      "A cheetah is running behind its prey. (Score: 0.4862)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.4407)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A cheetah chases prey on across a field.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A cheetah is running behind its prey. (Score: 0.8579)\n",
      "A monkey is playing drums. (Score: 0.5095)\n",
      "Two men pushed carts through the woods. (Score: 0.4753)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.4553)\n",
      "A man is riding a horse. (Score: 0.4446)\n",
      "A cheetah is running behind its prey. (Score: 0.8579)\n",
      "A monkey is playing drums. (Score: 0.5095)\n",
      "Two men pushed carts through the woods. (Score: 0.4753)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.4553)\n",
      "A man is riding a horse. (Score: 0.4446)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a simple application for sentence embeddings: semantic search\n",
    "\n",
    "We have a corpus with various sentences. Then, for a given query sentence,\n",
    "we want to find the most similar sentence in this corpus.\n",
    "\n",
    "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "def test4(embedder):\n",
    "\n",
    "    \n",
    "    # Corpus with example sentences\n",
    "    corpus = [\n",
    "        \"A man is eating food.\",\n",
    "        \"A man is eating a piece of bread.\",\n",
    "        \"The girl is carrying a baby.\",\n",
    "        \"A man is riding a horse.\",\n",
    "        \"A woman is playing violin.\",\n",
    "        \"Two men pushed carts through the woods.\",\n",
    "        \"A man is riding a white horse on an enclosed ground.\",\n",
    "        \"A monkey is playing drums.\",\n",
    "        \"A cheetah is running behind its prey.\",\n",
    "    ]\n",
    "    corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "    \n",
    "    # Query sentences:\n",
    "    queries = [\n",
    "        \"A man is eating pasta.\",\n",
    "        \"Someone in a gorilla costume is playing a set of drums.\",\n",
    "        \"A cheetah chases prey on across a field.\",\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(5, len(corpus))\n",
    "    for query in queries:\n",
    "        query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    \n",
    "        # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "        top_results = torch.topk(cos_scores, k=top_k)\n",
    "    \n",
    "        print(\"\\n\\n======================\\n\\n\")\n",
    "        print(\"Query:\", query)\n",
    "        print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "    \n",
    "        for score, idx in zip(top_results[0], top_results[1]):\n",
    "            print(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "    \n",
    "        # \"\"\"\n",
    "        # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "        hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "        hits = hits[0]      #Get the hits for the first query\n",
    "        for hit in hits:\n",
    "            print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
    "        # \"\"\"\n",
    "\n",
    "test4(model1)\n",
    "print(\"\\n\\n\")\n",
    "test4(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b876feb7-20cd-4bc5-91f9-3bb4a6e3009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: What is Python?\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Python is a programming language. (Score: 0.9118)\n",
      "I love python (Score: 0.7800)\n",
      "Python is one of the most popular language in AI development (Score: 0.6519)\n",
      "Python is better than Java. (Score: 0.5992)\n",
      "My first paragraph. That contains information (Score: 0.0640)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: What is Python?\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Python is a programming language. (Score: 0.8517)\n",
      "I love python (Score: 0.7958)\n",
      "Python is better than Java. (Score: 0.7570)\n",
      "Python is one of the most popular language in AI development (Score: 0.7310)\n",
      "My first paragraph. That contains information (Score: 0.5170)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test5(model):\n",
    "\n",
    "    docs = [\n",
    "        \"I love python\",\n",
    "        \"Python is one of the most popular language in AI development\",\n",
    "        \"Python is better than Java.\",\n",
    "        \"My first paragraph. That contains information\",\n",
    "        \"Python is a programming language.\",\n",
    "    ]\n",
    "    document_embeddings = model.encode(docs, convert_to_tensor=True)\n",
    "    \n",
    "    query = \"What is Python?\"\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    \n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, document_embeddings)[0]\n",
    "    top_k = min(5, len(docs))\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(docs[idx], \"(Score: {:.4f})\".format(score))\n",
    "\n",
    "test5(model1)\n",
    "test5(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd0f303-f079-45a7-b944-93970b703915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "model = CrossEncoder(\"./all-MiniLM-L6-v2\")\n",
    "\n",
    "scores = model.predict([[\"My first\", \"sentence pair\"], [\"Second text\", \"pair\"]])\n",
    "scores = model.predict(['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc592def-5540-4450-a4a5-92a3151d5a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at ./bge-reranker-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.055359140038490295\n",
      "[-0.22660410404205322, 0.17735664546489716]\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "reranker = FlagReranker('./bge-reranker-large', use_fp16=False) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "\n",
    "score = reranker.compute_score(['query', 'passage'])\n",
    "print(score)\n",
    "\n",
    "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2d8891-ee27-4afc-b420-2d7a473a7998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at ./bge-reranker-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2681, -0.0465])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./bge-reranker-large')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./bge-reranker-large')\n",
    "model.eval()\n",
    "\n",
    "pairs = [['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']]\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5f0a6d-10e2-4bad-acae-ac105adce05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0400845  -0.00561158]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a430e338-0ec6-464e-ae31-4cda4e9082cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This example computes the score between a query and all possible\n",
    "sentences in a corpus using a Cross-Encoder for semantic textual similarity (STS).\n",
    "It output then the most similar sentences for the given query.\n",
    "\"\"\"\n",
    "\n",
    "# from sentence_transformers.cross_encoder import CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "# # Pre-trained cross encoder\n",
    "model = CrossEncoder(\"cross-encoder/stsb-distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cc3cab7-6d5e-4eb3-b911-fa1440c3e2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: A man is eating pasta.\n",
      "0.67\tA man is eating food.\n",
      "0.34\tA man is eating a piece of bread.\n",
      "0.08\tA man is riding a horse.\n",
      "0.07\tA man is riding a white horse on an enclosed ground.\n",
      "0.01\tThe girl is carrying a baby.\n",
      "0.01\tTwo men pushed carts through the woods.\n",
      "0.01\tA monkey is playing drums.\n",
      "0.01\tA woman is playing violin.\n",
      "0.01\tA cheetah is running behind its prey.\n",
      "scores: [0.67323726 0.34102532 0.00542465 0.07569354 0.00525378 0.00536814\n",
      " 0.06676241 0.00534824 0.00516718]\n",
      "indices: [0 1 3 6 2 5 7 4 8]\n"
     ]
    }
   ],
   "source": [
    "# We want to compute the similarity between the query sentence\n",
    "query = \"A man is eating pasta.\"\n",
    "\n",
    "# With all sentences in the corpus\n",
    "corpus = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]\n",
    "\n",
    "# 1. We rank all sentences in the corpus for the query\n",
    "ranks = model.rank(query, corpus)\n",
    "\n",
    "# Print the scores\n",
    "print(\"Query:\", query)\n",
    "for rank in ranks:\n",
    "    print(f\"{rank['score']:.2f}\\t{corpus[rank['corpus_id']]}\")\n",
    "\n",
    "# 2. Alternatively, you can also manually compute the score between two sentences\n",
    "sentence_combinations = [[query, sentence] for sentence in corpus]\n",
    "scores = model.predict(sentence_combinations)\n",
    "\n",
    "# Sort the scores in decreasing order to get the corpus indices\n",
    "ranked_indices = np.argsort(scores)[::-1]\n",
    "print(\"scores:\", scores)\n",
    "print(\"indices:\", ranked_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da1061-7672-4ebc-9433-16f0bfa9c918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
